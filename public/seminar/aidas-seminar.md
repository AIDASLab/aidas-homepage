---
title: "AIDAS Seminar"
date: "2025-08-01"
summary: "AIDAS Seminar"
thumbnail: "seminar/thumbnails/aidas_seminar.png"
---


# Contents

|Date|Category|Topic|Presenter|
|----|--------|-----|---------|
|**Dec 5**|LLMs|Prismatic Synthesis: Gradient-based Data Diversification Boosts Generalization in LLM Reasoning|Yejoon Lee|
||LLMs|[HiFC: High-efficiency Flash-based KV Cache Swapping for Scaling LLM Inference](https://youtu.be/wJnABzHG-Sc)|Dogeun Kim|
|**Nov 28**|LLMs|MoBE: Mixture-of-Basis-Experts for Compressing MoE-based LLMs|Sieun Hyeon|
||Robotics|TBD|Hyeonggeun Kim|
|**Nov 21**|Reinforcement Learning|Mastering the game of Go with deep neural networks and tree search|Woohyeon Kim|
|**Nov 14**|LLMs|[ThinkMorph: Emergent Properties in Multimodal Interleaved Chain-of-Thought Reasoning](https://youtu.be/28qsnscO0Mk)|Yongha Lee|
||Representation Learning|[A Survey on Knowledge Graphs: Representation, Acquisition, and Applications](https://youtu.be/pZTLkm9Eg6Y)|Minwoo Kim|
|**Nov 7**|LLMs|[SparseD: Sparse Attention for Diffusion Language Models](https://youtu.be/lgI89eAFjLc)|Jinhyeok Kim|
|**Oct 31**|Representation Learning|[Concerto: Joint 2D-3D Self-Supervised Learning Emerges Spatial Representations](https://youtu.be/EcLrzBV2A3I)|Jusang Oh|
||LLMs|[Emergent Introspective Awareness in Large Language Models](https://youtu.be/0DTlY0UFXsY)|Steve Cho|
|**Oct 24**|Vector DB|[On the Theoretical Limitations of Embedding-Based Retrieval](https://youtu.be/I7xagaD1pt0?si=mvDvHnDUvIREs7AG)|Mintaek Lim|
||Multimodal LLMs|[DeepSeek-OCR: Contexts Optical Compression](https://youtu.be/QUkNdfPA3C0)|Jaeik Kim|
|**Oct 17**|Generative Models|[Video models are zero-shot learners and reasoners](https://youtu.be/2yDxmBOwfP4)|Jihwan Hong|
||LLMs|[Persona Vectors: Monitoring and Controlling Character Traits in Language Models](https://youtu.be/z6A0BLJS8UU)|Woojin Kim|
|**Oct 10**|LLMs|[Training and Inference on Any-Order Autoregressive Models the Right Way](https://youtu.be/HGUeMv7VVNE)|Yunseok Han|
||LLMs|[Dynamic Planning for LLM-based Graphical User Interface Automation](https://youtu.be/QMjsZ73GBoc?si=dhaQVruEEVkzdGU8)|Hanjun Lee|
|**Sep 26**|Robotics|[LLaDA-VLA: Vision-Language Diffusion Action Models](https://youtu.be/FVA3vbpteao)|Hoeun Lee|
||LLMs|[LLM Privacy Survey](https://www.youtube.com/watch?v=E0S3MVh0ghw)|Geun Choi|
|**Sep 19**|LLMs|[Mixture of Lookup Experts](https://youtu.be/vwOh7ET6oqw?si=B56gx3LvIIQbzC4z)|Sieun Hyeon|
||LLMs|[Self-Questioning Language Models](https://youtu.be/WDfvbILy2-I?si=47c3FJ6ySmJVsUxv)|Yejoon Lee|
|**Sep 12**|LLMs|[RoFormer: Enhanced Transformer with Rotary Position Embedding](https://youtu.be/5l9quUaJw7g)|Dogeun Kim|
||Robotics|[Latent Diffusion Planning for Imitation Learning](https://youtu.be/f0KKyqz1PH4?si=x5DmqINlO9fX6nKD)|Hyeonggeun Kim|
|**Aug 22**|LLMs|[Advancing Mobile GUI Agents: A Verifier-Driven Approach to Practical Deployment](https://youtu.be/Ce2VGxMOUNY)|Hanjun Lee|
||Multimodal LLMs|[Uni-MoE: Scaling Unified Multimodal LLMs with Mixture of Experts](https://youtu.be/J6PN_A5ggBk?si=k3C_KOJ4d0NdiMMK)|Woohyeon Park|
|**Aug 8**|LLMs|[SparseLoRA: Accelerating LLM Fine-Tuning with Contextual Sparsity](https://youtu.be/lrJOB66FAgk?si=mqFs73OuB9Z4g0T9)|Jinhyeok Kim|
||LLMs|[Subliminal Learning: Language Models Transmit Behavioral Traits via Hidden Signals in Data](https://youtu.be/dvvfOHv4tOI?si=rqJ3ssYYPGVqKzMn)|Steve Cho|
|**Jul 25**|Generative Models|[Train for the Worst, Plan for the Best: Understanding Token Ordering in Masked Diffusions](https://www.youtube.com/watch?v=4Yx4SESN88c)|Jaeik Kim|
||LLMs|[Mixture-of-Recursions: Learning Dynamic Recursive Depths for Adaptive Token-Level Computation](https://www.youtube.com/watch?v=KlA7JIAONO0)|Jusang Oh|
|**Jul 18**|Databases|[On the Rankability of Visual Embeddings](https://www.youtube.com/watch?v=aKIzYYBRGj0)|Mintaek Lim|
||LLMs|[KV-efficient language models: MLA and sliding window attention](https://www.youtube.com/watch?v=t2VYbYKHsdQ)|Yejoon Lee|


