---
title: "Agents Seminar"
date: "2025-07-31"
summary: "07/2025 – 09/2025 | Summer 2025 Agents Tutorial"
thumbnail: "seminar/thumbnails/agents_seminar.png"
---

## Overview

This series introduces modern AI agent systems from foundations to domain-specific applications, including coding and robotics.

## Curriculum

1. End-to-end agent workflow (planning, reasoning, memory)
2. Single-agent and multi-agent approaches
3. Memory and tool calling: RAG, RL for tool calling
4. Planning and reasoning frameworks: ReAct, Reflection
5. Domain-specific agents: Industry and mobile
6. Domain-specific agents: Robotics and coding

## Sessions

### Week 1: Introduction to AI Agent

#### Recording

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 800px; margin: 0 auto;"> 
  <iframe 
    src="https://www.youtube.com/embed/lCK9fvHlgdg?si=peyIta4N1GgSxAjj"
    style="position: absolute; top:0; left:0; width:100%; height:100%;"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>

This seminar video is the first week’s session of the AI Agent Seminar series. In this session, we explore what defines an AI agent, how it differs from traditional AI systems, and what core components—such as autonomy, perception, memory, reasoning, learning, and action—enable it to operate independently on behalf of users. We also examine recent research trends and real-world challenges surrounding the development and deployment of AI agents.

> **Presenter:** Yunseok Han

---

### Week 2: Multi-Agent System

#### Recording

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 800px; margin: 0 auto;"> 
  <iframe 
    src="https://www.youtube.com/embed/yz2UYjEDW8w?si=8SB78mDXa6Wt7pwY"
    style="position: absolute; top:0; left:0; width:100%; height:100%;"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>

This session introduces Multi-Agent Systems (MAS) as a paradigm to overcome the intrinsic limitations of single Large Language Models (LLMs), such as hallucination and scaling issues. The goal is to achieve collective intelligence, where the combined capabilities of multiple agents exceed the sum of their individual contributions. We cover the key components of MAS, provide a formal definition for agents and the system, and explore various collaboration mechanisms such as collaboration types, strategies including rule-based and role- based protocols, and communication structures of models. 

> **Presenter:** Sunghwan Steve Cho

---

### Week 3: Reasoning and Planning in LLM Agents

#### Recording

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 800px; margin: 0 auto;"> 
  <iframe 
    src="https://www.youtube.com/embed/9yDyOsleIaQ?si=ARCd9TIi98esJRFH"
    style="position: absolute; top:0; left:0; width:100%; height:100%;"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>

This seminar explains why the limitations of LLMs themselves can be overcome through the architecture of multi-agent systems. In addition, it provides an overview of memory systems and tool usage—two core components of multi-agent systems—along with related studies and future research directions.

> **Presenter:** Sieun Hyeon

---

### Week 4: Reasoning and Planning 

#### Recording

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 800px; margin: 0 auto;"> 
  <iframe 
    src="https://www.youtube.com/embed/rGgqzKFxi3U?si=yNdNlf_I6pzXyE2B"
    style="position: absolute; top:0; left:0; width:100%; height:100%;"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>

This seminar is the fourth week's session of the AI Agent Seminar series, focusing on the evolution and analysis of reasoning in large language models (LLMs). We cover the progression from chain-of-thought prompting and self-consistency to advanced frameworks such as Tree of Thought, ReAct, HuggingGPT, and Plan-and-Act, alongside the paradigm of test-time scaling that underpins recent reasoning models like OpenAI’s o1 and DeepSeek’s large-scale open-source systems. We further examine reinforcement learning with verifiable rewards (RLVR) as a standard training recipe for reasoning models, the challenges of overthinking and the taxonomy of efficient reasoning approaches, as well as scaling laws that highlight predictable improvements with increased test-time compute. Finally, we discuss mechanistic interpretability—analyzing hidden states, neurons, and circuits—to investigate whether model outputs genuinely reflect internal computation and to identify pathways for refining and aligning LLM reasoning.

> **Presenter:** Yunseok Han

---

### Week 5: Domain-Specific Agent − DeepResearch Analysis

#### Recording

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 800px; margin: 0 auto;"> 
  <iframe 
    src="https://www.youtube.com/embed/7PyPAJJ4iZ8?si=KQwGh1CnEvpytOWN"
    style="position: absolute; top:0; left:0; width:100%; height:100%;"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>

This seminar explores the evolution of information-seeking paradigms in the era of large language model (LLM) agents, focusing on the emerging concept of Agentic Deep Research. We connect two recent advances: the conceptual framework of reasoning-driven search, as proposed in From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agent, and the practical reinforcement learning framework introduced in DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments. Together, these works illustrate how LLM-based agents can move beyond static retrieval or prompt-engineered behaviors, toward autonomous systems capable of iterative reasoning, dynamic web search, and adaptive problem-solving in noisy real-world environments. The seminar highlights methodological trajectories, RL-based training strategies, and benchmark evaluations, while also discussing challenges such as scalability, transparency, and domain specialization. By examining these complementary contributions, we aim to showcase Deep Research as a concrete and promising direction in advancing agentic LLM systems.

> **Presenter:** Hanjun Lee

---

### Week 6: Domain-Specific Agent − Coding and Robotics

#### Recording

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 800px; margin: 0 auto;"> 
  <iframe 
    src="https://www.youtube.com/embed/rimKTGp2DiI?si=u19dwtmn3JSX3-Ms"
    style="position: absolute; top:0; left:0; width:100%; height:100%;"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>

This talk explores domain-specific AI agents across two arenas—repo-level coding and robotics—and argues that tool design + orchestration strategy is the key to real-world performance. On the coding side, we use CODEAGENT and its CODEAGENTBENCH to show how agents equipped with practical tools (web/doc search, symbol navigation, formatting, in-repo execution) outperform snippet-only approaches. On the robotics side, we map the same principles to embodied settings. Across both domains, the takeaway is consistent: realistic evaluation plus the right tools and clear agent schemas turn LLMs from text generators into reliable problem-solvers for complex, real systems.

> **Presenter:** Hyeonggeun Kim
