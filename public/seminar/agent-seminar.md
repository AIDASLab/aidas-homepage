---
title: "Agents Seminar"
date: "2025-07-31"
summary: "07/2025 – 09/2025 | Summer 2025 Agents Tutorial"
thumbnail: "seminar/thumbnails/agents_seminar.png"
---

# Curriculum
### 1. Agent e2e workflow (e.g., Planning, reasoning, memory, etc)
### 2. Single-, Multi-Agent Approaches
### 3. Memory, Tool-calling
- RAG , RL for Tool-calling 
### 4. Planning, Reasoning
- ReAct , Reflection 
### 5. Domain-specific agent
- Industry
- Mobile
### 6. Domain-specific agent
- Robot
- Coding

&nbsp;
&nbsp;

# Contents
## Week 1: Introduction to AI Agent

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 800px; margin: 0 auto;"> 
  <iframe 
    src="https://www.youtube.com/embed/lCK9fvHlgdg?si=peyIta4N1GgSxAjj"
    style="position: absolute; top:0; left:0; width:100%; height:100%;"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>

This seminar video is the first week’s session of the AI Agent Seminar series. In this session, we explore what defines an AI agent, how it differs from traditional AI systems, and what core components—such as autonomy, perception, memory, reasoning, learning, and action—enable it to operate independently on behalf of users. We also examine recent research trends and real-world challenges surrounding the development and deployment of AI agents.

Presenter: Yunseok Han

&nbsp;

## Week 2: Multi-Agent System

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 800px; margin: 0 auto;"> 
  <iframe 
    src="https://www.youtube.com/embed/yz2UYjEDW8w?si=8SB78mDXa6Wt7pwY"
    style="position: absolute; top:0; left:0; width:100%; height:100%;"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>

This session introduces Multi-Agent Systems (MAS) as a paradigm to overcome the intrinsic limitations of single Large Language Models (LLMs), such as hallucination and scaling issues. The goal is to achieve collective intelligence, where the combined capabilities of multiple agents exceed the sum of their individual contributions. We cover the key components of MAS, provide a formal definition for agents and the system, and explore various collaboration mechanisms such as collaboration types, strategies including rule-based and role- based protocols, and communication structures of models. 

Presenter: Sunghwan Steve Cho

&nbsp;

## Week 3: Reasoning and Planning in LLM Agents

*[The video will be released Soon.]*

Presenter: Sieun Hyeon


## Week 4: Domain-Specific Agent − Coding and Robotics

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 800px; margin: 0 auto;"> 
  <iframe 
    src="https://www.youtube.com/embed/rGgqzKFxi3U?si=yNdNlf_I6pzXyE2B"
    style="position: absolute; top:0; left:0; width:100%; height:100%;"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>

This seminar is the fourth week's session of the AI Agent Seminar series, focusing on the evolution and analysis of reasoning in large language models (LLMs). We cover the progression from chain-of-thought prompting and self-consistency to advanced frameworks such as Tree of Thought, ReAct, HuggingGPT, and Plan-and-Act, alongside the paradigm of test-time scaling that underpins recent reasoning models like OpenAI’s o1 and DeepSeek’s large-scale open-source systems. We further examine reinforcement learning with verifiable rewards (RLVR) as a standard training recipe for reasoning models, the challenges of overthinking and the taxonomy of efficient reasoning approaches, as well as scaling laws that highlight predictable improvements with increased test-time compute. Finally, we discuss mechanistic interpretability—analyzing hidden states, neurons, and circuits—to investigate whether model outputs genuinely reflect internal computation and to identify pathways for refining and aligning LLM reasoning.

Presenter: Yunseok Han


## Week 5: Domain-Specific Agent − DeepResearch Analysis

<div style="position: relative; padding-bottom: 56.25%; height: 0; overflow: hidden; max-width: 800px; margin: 0 auto;"> 
  <iframe 
    src="https://www.youtube.com/embed/7PyPAJJ4iZ8?si=KQwGh1CnEvpytOWN"
    style="position: absolute; top:0; left:0; width:100%; height:100%;"
    frameborder="0"
    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"
    allowfullscreen>
  </iframe>
</div>

This seminar explores the evolution of information-seeking paradigms in the era of large language model (LLM) agents, focusing on the emerging concept of Agentic Deep Research. We connect two recent advances: the conceptual framework of reasoning-driven search, as proposed in From Web Search towards Agentic Deep Research: Incentivizing Search with Reasoning Agent, and the practical reinforcement learning framework introduced in DeepResearcher: Scaling Deep Research via Reinforcement Learning in Real-world Environments. Together, these works illustrate how LLM-based agents can move beyond static retrieval or prompt-engineered behaviors, toward autonomous systems capable of iterative reasoning, dynamic web search, and adaptive problem-solving in noisy real-world environments. The seminar highlights methodological trajectories, RL-based training strategies, and benchmark evaluations, while also discussing challenges such as scalability, transparency, and domain specialization. By examining these complementary contributions, we aim to showcase Deep Research as a concrete and promising direction in advancing agentic LLM systems.

Presenter: Hanjun Lee